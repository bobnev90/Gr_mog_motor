#!!!Nur fur Jupyter notebook (Breitbild - 90%)
#from IPython.display import display, HTML
#display(HTML("<style>.container { width:90% !important; }</style>"))

import math
import machine_learning_datasets as ml
import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import metrics, linear_model, tree, naive_bayes, neighbors, ensemble, neural_network, svm, decomposition, manifold
import matplotlib.pyplot as plt 
from rulefit import RuleFit
import statsmodels.api as sm
from interpret.glassbox import ExplainableBoostingClassifier
from interpret import show
from interpret.perf import ROC
import matplotlib.pyplot as plt
import seaborn as sns

cvd_df = pd.read_csv("!!!Pannenstatistik_202205_ENDLICH.csv") #Ausfallstatistik der Erntemaschine
cvd_df.info() #Es ist notwendig, Daten auf die Maschinen herunterzuladen

cvd_df['age'] =  cvd_df['age'] / 365 #Das Alter wird als Differenz zwischen dem Produktionsdatum und dem aktuellen Datum gespeichert. (Tage)

#Fehlerüberprüfung
cvd_df.describe().transpose()

#-----------------------------------------------------------------------------------------------------------------------------------------
#подготовка данных

#РЕЧЬ ИДЕТ ОБ ОБОРОТАХ МОТОРА, НЕ ПУТАТЬ С ОБОРОТАМИ ВАЛА ОТБОРА МОЩНОСТИ!!!!!!!
#(RUS) Проверка на обороты. Средние обороты (интенсивность работы машины) не может быть больше 5000 оборотов.
#макс. обороты не могут быть больше 7000 (оборотов)
cvd_df = cvd_df[(cvd_df['t_avg'] <= 5000) & (cvd_df['t_avg'] > 0)].reset_index(drop=True)
cvd_df = cvd_df[(cvd_df['t_max'] <= 7000) & (cvd_df['t_max'] > 0)].reset_index(drop=True)
cvd_df = cvd_df[cvd_df['t_max'] >= cvd_df['t_avg']].reset_index(drop=True) #максимальные обороты не могут быть больше средних

cvd_df = cvd_df[cvd_df['age'] >= cvd_df['t_avg']].reset_index(drop=True) # - возраст мотора не может быть больше возраста машины. Новые машины с БУ двигателями исключаем

cvd_df = cvd_df[(cvd_df['p_consumpt'] <= 20) & (cvd_df['p_consumpt'] > 0)].reset_index(drop=True) #расход дизеля на Га
cvd_df = cvd_df[(cvd_df['o_consumpt'] <= 10) & (cvd_df['o_consumpt'] > 0)].reset_index(drop=True) #расход масла на Га

#проставим машины, где был даунгрейд (двигатель вскрывался, меняли форсунки)
ORD_NUM_END = ['RUS', 'BLS', 'RU4', 'UKR', 'UK4', 'POL', 'PO4', 'HU4', 'KAZ', 'KZ4'] #отметки того, что двигатель на замену. Последние 3 символа в номере заказа!!!

is_dwngrd = cvd_df['OFFERING_NUM_END'].isin(ORD_NUM_END)
cvd_df['WAS_DOWNGRADED'] = 0
cvd_df.loc[is_dwngrd, 'WAS_DOWNGRADED'] = 1

#повышение температуры. Даже при разовом наблюдении скачка температуры выше 105 град - говрит о серьезном нарушении системы охлаждения.
#переведем показатель МАКС температура в булиан - проблема с охлаждением
#при этом температура выше 200 градусов говорит о повреждении датчика, аварии или ошибке БД
cvd_df = cvd_df[(cvd_df['MAX_ENGINE_TEMP'] <= 200)].reset_index(drop=True)
cvd_df['COOLER_PROBLEM'] = cvd_df['MAX_ENGINE_TEMP'].apply(lambda x: 1 if x > 105 else 0)

#==========================================================================================================================================
#Вначале посмотрим, на сколько хорошо мы можем оценивать показатель "через сколько гектар надо делать ремонт двигателя"

rand = 7
y = cvd_df['HA_BEFORE_CRASH']
X = cvd_df.drop(['HA_BEFORE_CRASH'], axis=1).copy()
X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y, test_size=0.2, random_state=rand)

#разберем 6 моделей для линейной модели: линейная регрессия, полином, интерсекция, ДПР, рандомДПР, МЛП-регрессия (!!!не путать с МЛП классификатор!!!)
#ПЫТАЕМСЯ ОЦЕНИТЬ СКОЛЬКО ГЕКТАР ДО ПОЛОМКИ (HA_BEFORE_CRASH - ПОКАЗАТЕЛЬ ГА ДО ПОЛОМКИ)

reg_models = {

        'linear':{'model': linear_model.LinearRegression()}, 
        'linear_poly':{'model': make_pipeline(PolynomialFeatures(degree=2), linear_model.LinearRegression(fit_intercept=False)) },
        'linear_interact':{'model': make_pipeline(PolynomialFeatures(interaction_only=True), linear_model.LinearRegression(fit_intercept=False)) },
        'decision_tree':{'model': tree.DecisionTreeRegressor(max_depth=5, random_state=rand)},
        'random_forest':{'model':ensemble.RandomForestRegressor(max_depth=7, random_state=rand)}, 
        'mlp':{'model':neural_network.MLPRegressor(hidden_layer_sizes=(15,15,15), max_iter=300, 
                                                   early_stopping=True, random_state=rand)}

#СФОРМИРУЕМ ТАБЛИЦУ С РЕЗУЛЬТАТОМ

for model in reg_models.keys():
    #print(model)
    fitted_model = reg_models[model]['model'].fit(X_train, y_train_reg)
    y_train_pred = fitted_model.predict(X_train.values)
    y_test_pred = fitted_model.predict(X_test.values)
    reg_models[model]['fitted'] = fitted_model
    reg_models[model]['preds'] = y_test_pred
    reg_models[model['RMSE_train'] = math.sqrt(metrics.mean_squared_error(y_train_reg, y_train_pred))
    reg_models[model]['RMSE_test'] = math.sqrt(metrics.mean_squared_error(y_test_reg, y_test_pred))
    reg_models[model]['R2_test'] = metrics.r2_score(y_test_reg, y_test_pred)

#СМОТРИМ МЕТРИКИ 
reg_metrics = pd.DataFrame.from_dict(reg_models, 'index')[['RMSE_train', 'RMSE_test', 'R2_test']]
reg_metrics.sort_values(by='RMSE_test')

#R2 у всех моедеолй ниже 10%. Связанос тем, что слишком большой разбег, если с двигателдем все ОК он может проработать и 100 Га и 1000 Га и 10000 Га + не учитываем фактор капитального ремонта.
#Вывод: НАДО СМОТРЕТЬ МОДЕЛИ КЛАССИФИКАТОРЫ


#Будем смотреть модели классификации

#Classification method

class_models = {
        'logistic':{'model': linear_model.LogisticRegression()}, 
        'decision_tree':{'model': tree.DecisionTreeClassifier(max_depth=7, random_state=rand)},
        'gradient_boosting':{'model':ensemble.GradientBoostingClassifier(n_estimators=210)},
        'random_forest':{'model':ensemble.RandomForestClassifier(max_depth=11,\
                                                                 class_weight='balanced', random_state=rand)},
        'mlp':{'model':make_pipeline(StandardScaler(),\
                                     neural_network.MLPClassifier(hidden_layer_sizes=(7,7), max_iter=500,\
                                                   early_stopping=True, random_state=rand))}
    }

for model_name in class_models.keys():
    fitted_model = class_models[model_name]['model'].fit(X_train, y_train_class)
    y_train_pred = fitted_model.predict(X_train.values)
    if model_name == 'ridge':
        y_test_pred = fitted_model.predict(X_test.values) 
    else:
        y_test_prob = fitted_model.predict_proba(X_test.values)[:,1]
        y_test_pred = np.where(y_test_prob > 0.5, 1, 0)
    class_models[model_name]['fitted'] = fitted_model
    class_models[model_name]['probs'] = y_test_prob
    class_models[model_name]['preds'] = y_test_pred
    class_models[model_name]['Accuracy_train'] = metrics.accuracy_score(y_train_class, y_train_pred)
    class_models[model_name]['Accuracy_test'] = metrics.accuracy_score(y_test_class, y_test_pred)
    class_models[model_name]['Recall_train'] = metrics.recall_score(y_train_class, y_train_pred)
    class_models[model_name]['Recall_test'] = metrics.recall_score(y_test_class, y_test_pred)
    if model_name != 'ridge':
        class_models[model_name]['ROC_AUC_test'] = metrics.roc_auc_score(y_test_class, y_test_prob)
    else:
        class_models[model_name]['ROC_AUC_test'] = 0
    class_models[model_name]['F1_test'] = metrics.f1_score(y_test_class, y_test_pred)
    class_models[model_name]['MCC_test'] = metrics.matthews_corrcoef(y_test_class, y_test_pred)

#Сравним метрики

class_metrics = pd.DataFrame.from_dict(class_models, 'index')[['Accuracy_train', 'Accuracy_test',\
                                                               'Recall_train', 'Recall_test',\
                                                               'ROC_AUC_test', 'F1_test', 'MCC_test']]
class_metrics.sort_values(by='ROC_AUC_test', ascending=False)

  #Максимальный опять MLP и теперь уже показатели стабильные
#Indikatoren sind zuverlässig. 
#In Zukunft werden wir neuronale Netze verwenden, um die Möglichkeit eines Ausfalls des Motors und möglicherweise anderer Teile des Mähdreschers vorherzusagen.


#-------------------------------------------------------------------------
#ROC AUC

plt.figure(figsize = (14,14))
plt.tick_params(axis = 'both', which = 'major', labelsize = 12)
fpr, tpr, _ = metrics.roc_curve(y_test_class, class_models['mlp']['probs'])
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % class_models['mlp']['ROC_AUC_test'])
plt.plot([0, 1], [0, 1], 'k--') 
plt.xlabel('FRP', fontsize = 12)
plt.ylabel('TPR', fontsize = 12)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.legend(loc="lower left")


#----------------------------------------------------------------------------
#Также еще попробуем классическую бустинговую модель
ebm_model = ExplainableBoostingClassifier()
ebm_model.fit(X_train, y_train_class)


#посмотрим значимые коэффициенты при помощи методом перстановки важности признаков (будем рандомно перетасовывать признаки и смотреть увеличилась ли ошибка. 
#ЕСЛИ ОШИБКА НЕ МЕНЯЕТСЯ ПРИЗНАК НЕ ЗНАЧИМ, ЕСЛИ МЕНЯЕТСЯ - ТО ОСТАВЛЯЕМ. (ЛИШНИЕ ПРИЗНАКИ МОГУТ ПРИВЕЗТИ К ПЕРЕОБУЧЕНИЮ МОДЕЛИ

#PFI

#РАСЧИТАЕМ ДЛЯ КАЖДОГО PFI
for model_name in class_models.keys():
    fitted_model = class_models[model_name]['fitted']
    permutation_imp = inspection.permutation_importance(\
                        fitted_model, X_test, y_test, n_jobs=-1,\
                        scoring='accuracy', n_repeats=8,\
                        random_state=rand)
    class_models[model_name]['importances_mean'] =\
                        permutation_imp.importances_mean

#ПРОСТАВИМ В ТАБЛИЦУ
perm_imp_df = pd.DataFrame({
        'name': X_train.columns,\
                'dt_imp': class_models['decision_tree']['importances_mean'],\
                'gb_imp': class_models['gradient_boosting']['importances_mean'],\
                'rf_imp': class_models['random_forest']['importances_mean'],\
                'log_imp': class_models['logistic']['importances_mean'],\
                'mlp_imp': class_models['mlp']['importances_mean']}).\
            reset_index(drop=True)

#ПОСЧИТАЕМ СРЕДНЕЕ ДЛЯ КАЖДОЙ ДЛЯ КАЖДОГО ПОКАЗАТЕЛЯ
perm_imp_df['avg_imp'] = (perm_imp_df['dt_imp'] + perm_imp_df['gb_imp'] +\
                         perm_imp_df['rf_imp'] + perm_imp_df['log_imp'] +\
                         perm_imp_df['mlp_imp'])/6

#ПОКАЖЕМ ОТСОРТИРОВАННУЮ ТАБЛИЦУ ЗНАЧИМОСТИ КАЖДОГО ПОКАЗАТЕЛЯ
perm_imp_sorted_df = perm_imp_df.round(5).\
    sort_values(by='avg_imp', ascending=False)
perm_imp_sorted_df.style.\
    background_gradient(cmap='viridis_r', low=0, high=0.2,\
                        subset=['dt_imp', 'gb_imp', 'rf_imp',\
                                'log_imp',  'mlp_imp'])

#ВЫВЕДЕМ ЗНАЧИМОСТЬ ПОКАЗАТЕЛДЕЙ ГРАФИЧЕСКИ. ПРОСТО НАПРОТИВ КАЖДОГО ПОКАЗАТЕЛЯ ПОСТРОИМ СРЕДНЕЕ ЗНАЧЕНИЕ И РАЗБРОС. КАК В СРЕДНЕМ ПОКАЗАТЕЛЬ ВЛИЯЕТ НА РЕЗУЛЬТАТ

#!!!!!!!!!!!!!!!!!!!!!!!
#!!!!!!!!!!!!!!!ПЕРЕДЕЛАЛ ЗА РУСЛАНОМ!!!!! В ЕГО КОДЕ БЫЛА УСТАРЕВШАЯ ВЕРСИЯ pdpbox. ИЗМЕНИЛАСЬ ОРФОГРАФИЯ.

for i in range(len(feature_names)):
    pdp_feat_df = pdp.PDPIsolate(\
        model=class_models['gradient_boosting']['fitted'],\
        df=pd.concat((X_test, y_test), axis=1),\
        model_features=X_test.columns,\
        feature=feature_names[i], feature_name="properties"
    )
    fig, axes = pdp_feat_df.plot(
    center=False,
    plot_lines=False,
    plot_pts_dist=False,
    to_bins=False,
    engine='matplotlib'
    )
